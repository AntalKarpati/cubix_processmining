{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T21:25:26.350279Z",
     "start_time": "2025-01-14T21:25:20.692993Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install Faker",
   "id": "15198142b5634d80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Faker\r\n",
      "  Obtaining dependency information for Faker from https://files.pythonhosted.org/packages/c2/01/6acc8b4dba4154cd93b444382a9ad3c099557aac577bdc7d66373e0a0c68/Faker-33.3.1-py3-none-any.whl.metadata\r\n",
      "  Downloading Faker-33.3.1-py3-none-any.whl.metadata (15 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /Users/m0rz3n/PycharmProjects/cubix_processmining/script/lib/python3.9/site-packages (from Faker) (2.9.0.post0)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/m0rz3n/PycharmProjects/cubix_processmining/script/lib/python3.9/site-packages (from Faker) (4.12.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/m0rz3n/PycharmProjects/cubix_processmining/script/lib/python3.9/site-packages (from python-dateutil>=2.4->Faker) (1.17.0)\r\n",
      "Downloading Faker-33.3.1-py3-none-any.whl (1.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.9/1.9 MB\u001B[0m \u001B[31m10.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: Faker\r\n",
      "Successfully installed Faker-33.3.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-14T21:53:51.230376Z",
     "start_time": "2025-01-14T21:53:50.719165Z"
    }
   },
   "source": [
    "import csv\n",
    "import random\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Adatok generálása\n",
    "num_customers = 500\n",
    "num_products = 200\n",
    "num_orders = 3000\n",
    "\n",
    "# 1. customers.csv\n",
    "with open('customers.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"customer_id\", \"name\", \"signup_date\", \"country\"])\n",
    "    for customer_id in range(1, num_customers + 1):\n",
    "        name = fake.name()\n",
    "        signup_date = fake.date_this_decade().strftime('%Y-%m-%d')\n",
    "        country = random.choice([\"Hungary\", \"USA\", \"Germany\", \"UK\", \"France\"])\n",
    "        writer.writerow([customer_id, name, signup_date, country])\n",
    "\n",
    "# 2. products.csv\n",
    "with open('products.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"product_id\", \"product_name\", \"category\"])\n",
    "    for product_id in range(1, num_products + 1):\n",
    "        product_name = f\"Product {product_id}\"\n",
    "        category = random.choice([\"Electronics\", \"Furniture\", \"Clothing\", \"Books\", \"Toys\"])\n",
    "        writer.writerow([product_id, product_name, category])\n",
    "\n",
    "# 3. orders.csv\n",
    "orders_data = []\n",
    "with open('orders.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"order_id\", \"customer_id\", \"order_date\", \"total_amount\"])\n",
    "    for order_id in range(1, num_orders + 1):\n",
    "        customer_id = random.randint(1, num_customers)\n",
    "        order_date = (datetime.today() - timedelta(days=random.randint(1, 365))).strftime('%Y-%m-%d')\n",
    "        total_amount = round(random.uniform(100, 5000))\n",
    "        orders_data.append({\"order_id\": order_id, \"total_amount\": total_amount})  # Save orders for later reference\n",
    "        writer.writerow([order_id, customer_id, order_date, total_amount])\n",
    "\n",
    "# 4. order_details.csv\n",
    "order_details_data = []\n",
    "with open('order_details.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"order_id\", \"product_id\", \"quantity\", \"price_per_unit\"])\n",
    "    for order_id in range(1, num_orders + 1):\n",
    "        num_items = random.randint(1, 5)\n",
    "        order_total_calculated = 0  # Reset for each order\n",
    "        for _ in range(num_items):\n",
    "            product_id = random.randint(1, num_products)\n",
    "            quantity = random.randint(1, 3)\n",
    "            price_per_unit = round(random.uniform(50, 1000))\n",
    "            order_total_calculated += price_per_unit * quantity  # Add to the total order amount\n",
    "            writer.writerow([order_id, product_id, quantity, price_per_unit])\n",
    "\n",
    "        # Now update the corresponding order's total amount if the calculated total differs\n",
    "        for order in orders_data:\n",
    "            if order['order_id'] == order_id:\n",
    "                # Adjust the total amount to match the calculated total from order_details\n",
    "                order['total_amount'] = round(order_total_calculated, 2)\n",
    "\n",
    "# Rewriting the orders.csv with updated total amounts from order_details.csv\n",
    "with open('orders.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"order_id\", \"customer_id\", \"order_date\", \"total_amount\"])\n",
    "    for order in orders_data:\n",
    "        customer_id = random.randint(1, num_customers)\n",
    "        order_date = (datetime.today() - timedelta(days=random.randint(1, 365))).strftime('%Y-%m-%d')\n",
    "        writer.writerow([order['order_id'], customer_id, order_date, order['total_amount']])\n",
    "\n",
    "print(\"CSV fájlok sikeresen generálva és módosítva!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV fájlok sikeresen generálva és módosítva!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T21:30:47.662771Z",
     "start_time": "2025-01-14T21:30:47.652361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "print(\"Aktuális munkakönyvtár:\", os.getcwd())"
   ],
   "id": "5cd2d5206d3a9c60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuális munkakönyvtár: /Users/m0rz3n/PycharmProjects/cubix_processmining/support_files\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b8bda4c3c3778d0e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
